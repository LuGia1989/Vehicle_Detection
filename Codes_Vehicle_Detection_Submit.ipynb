{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection using HOG and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import pickle\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.measurements import label\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Helper Function for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# While it could be cumbersome to include three color channels of a full resolution \n",
    "# image, you can perform spatial binning on an image and still retain enough information \n",
    "# to help in finding vehicles. \n",
    "def bin_spatial(img, size=(32, 32), print_flag = 'no'):\n",
    "    \"\"\"\n",
    "    resize image to a desize size and \n",
    "    fatten out to a feature vector.\n",
    "    \"\"\"\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    if (print_flag == 'yes'):\n",
    "        plt.plot(features)\n",
    "        plt.title('Spatially Binned Features')\n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "\n",
    "# Histogram of Color is useful in the case when objects appear slightly different in aspects and orientations\n",
    "# are still be matched.\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256), print_flag = 'no'):\n",
    "    \"\"\"\n",
    "    find color histogram for RGB channels and concatenate to a feature vector.\n",
    "    Plot to visual R,G,B histogram graphs.\n",
    "    \"\"\"\n",
    "    # Compute the histogram of the color channels separately\n",
    "    rhist = np.histogram(img[:, :, 0], bins=nbins, range=bins_range)\n",
    "    ghist = np.histogram(img[:, :, 1], bins=nbins, range=bins_range)\n",
    "    bhist = np.histogram(img[:, :, 2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((rhist[0], ghist[0], bhist[0]))\n",
    "    # Generating bin centers\n",
    "    bin_edges = rhist[1]\n",
    "    bin_centers = (bin_edges[1:] + bin_edges[0:len(bin_edges) - 1]) / 2\n",
    "    # Plot a figure with all three bar charts\n",
    "    if (print_flag == 'yes'):\n",
    "        if (rhist is not None) or (ghist is not None) or (bhist is not None):\n",
    "            fig = plt.figure(figsize=(12, 3))\n",
    "            plt.subplot(131)\n",
    "            plt.bar(bin_centers, rhist[0])\n",
    "            plt.xlim(0, 256)\n",
    "            plt.title('R Histogram')\n",
    "            plt.subplot(132)\n",
    "            plt.bar(bin_centers, ghist[0])\n",
    "            plt.xlim(0, 256)\n",
    "            plt.title('G Histogram')\n",
    "            plt.subplot(133)\n",
    "            plt.bar(bin_centers, bhist[0])\n",
    "            plt.xlim(0, 256)\n",
    "            plt.title('B Histogram')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print('Your function is returning None for at least one variable...')\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# HOG is good for distinguish gradient features\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True, print_flag='no'):\n",
    "    \"\"\"\n",
    "    Given orientations, pixels_per_cell and cell_per_block, compute the hog features \n",
    "    of a image.\n",
    "    If visual option is True, we can display the hog image on the graph.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=False, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        if (print_flag == 'yes'):\n",
    "            # Plot the examples\n",
    "            fig = plt.figure()\n",
    "            plt.subplot(121)\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            plt.title('Example Car Image')\n",
    "            plt.subplot(122)\n",
    "            plt.imshow(hog_image, cmap='gray')\n",
    "            plt.title('HOG Visualization')\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=False, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "\n",
    "    \n",
    "# Method to combine all three sptial binning, histogram of color, and HOG features    \n",
    "def extract_features(imgs, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256),orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0):\n",
    "    \"\"\"\n",
    "    Method to convert image to different color space and combine hog feature, histogram \n",
    "    of color features, and spatial bin color features into a single feature vector\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a list to append feature vectors\n",
    "    features = []\n",
    "    for file in imgs:\n",
    "        image = mpimg.imread(file)\n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif cspace == 'YCRCB':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: feature_image = np.copy(image)\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))\n",
    "            hog_features = np.ravel(hog_features)        \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins, bins_range = hist_range)\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        features.append(np.concatenate((hog_features,spatial_features,hist_features)))\n",
    "    # Return list of feature vectors\n",
    "    return features    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "#### (a). Plot car and non-car image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load cars and non-cars dataset\n",
    "car_files = glob.glob('vehicles/vehicles/*/*.png')\n",
    "noncar_files = glob.glob('non-vehicles/non-vehicles/*/*.png')\n",
    "print(\"Number of car images: \",len(car_files))\n",
    "print(\"Number of non-car images: \",len(noncar_files))\n",
    "# randomize the index of cars and noncars dataset\n",
    "car_idx = np.random.randint(len(car_files) - 1)\n",
    "noncar_idx = np.random.randint(len(noncar_files) - 1)\n",
    "\n",
    "img_car = mpimg.imread(car_files[car_idx])\n",
    "img_noncar = mpimg.imread(noncar_files[noncar_idx])\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(5,2.5))\n",
    "ax1.imshow(img_car)\n",
    "ax1.set_title('Car Image',fontsize=15)\n",
    "ax2.imshow(img_noncar)\n",
    "ax2.set_title('Non-car Image', fontsize=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b). Visualize Hog, Color Histogram and Spatial Binned Features for a car image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just create a HOG parameters to display the HOG image/features\n",
    "colorspace = 'YCRCB' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = 0 # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_feat = True  # Spatial features on or off\n",
    "hist_feat = True  # Histogram features on or off\n",
    "hog_feat = True  # HOG features on or off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# spatial binning of car image\n",
    "bin_features = bin_spatial(img_car, size=(32, 32), print_flag = 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOG visualization below with gradient directions are shown.  As you can see the shape of the car is almost standout in the HOG visualization plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HOG features\n",
    "img_car = img_car[:,:,0]\n",
    "hog_car = get_hog_features(img_car, orient=orient, pix_per_cell=pix_per_cell, \n",
    "                                cell_per_block= cell_per_block, vis=True, feature_vec=False, \n",
    "                                print_flag='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c). Visualize combined and normalized features for a car and non-car image\n",
    "Below is the combined feature vectors of the car and non-car before normalization and after normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "car_features = extract_features(car_files, cspace=colorspace,\n",
    "                                orient=orient, pix_per_cell=pix_per_cell,\n",
    "                                cell_per_block=cell_per_block,\n",
    "                                hog_channel=hog_channel)\n",
    "print ('Car samples: ', len(car_features))\n",
    "notcar_features = extract_features(noncar_files, cspace=colorspace,\n",
    "                                   orient=orient, pix_per_cell=pix_per_cell,\n",
    "                                   cell_per_block=cell_per_block,\n",
    "                                   hog_channel=hog_channel)\n",
    "print ('Notcar samples: ', len(notcar_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an array stack of feature vectors\n",
    "x = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "# Fit a per-column scaler\n",
    "x_scaler = StandardScaler().fit(x)\n",
    "# Apply the scaler to X\n",
    "scaled_x = x_scaler.transform(x)\n",
    "# Plot an example of raw and scaled features\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(img_car, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.subplot(132)\n",
    "print('car index: ', car_idx)\n",
    "plt.plot(x[car_idx])\n",
    "plt.title('Raw Features')\n",
    "plt.subplot(133)\n",
    "plt.plot(scaled_x[car_idx])\n",
    "plt.title('Normalized Features')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Final parameters \n",
    "colorspace = 'YCRCB' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (32,32)\n",
    "hist_range = (0,256)\n",
    "hist_bins = 32\n",
    "\n",
    "\n",
    "def svm (car_files,noncar_files,cspace=colorspace,spatial_size=spatial_size,hist_bins=hist_bins, \n",
    "         hist_range=hist_range,orient=orient,pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "         hog_channel=hog_channel):\n",
    "    \"\"\"\n",
    "    Stack car and non-car feature vectors and normalize them before fitting into a Linear SVM.\n",
    "    Give SVM prediction and compute time for both SVM train and prediction.\n",
    "    \"\"\"\n",
    "    \n",
    "    car_features = extract_features(car_files, cspace=colorspace, spatial_size=spatial_size,\n",
    "                        hist_bins=hist_bins, hist_range=hist_range,orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel)\n",
    "    noncar_features = extract_features(noncar_files, cspace=colorspace, spatial_size=spatial_size,\n",
    "                        hist_bins=hist_bins, hist_range=hist_range,orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel)\n",
    "\n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features, noncar_features)).astype(np.float64)                        \n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "\n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(noncar_features))))\n",
    "\n",
    "    # Split up data into randomized training and test sets\n",
    "    rand_state = np.random.randint(0, 100)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "    \n",
    "    print('Using:',orient,'orientations',pix_per_cell,\n",
    "        'pixels per cell and', cell_per_block,'cells per block')\n",
    "    print('Feature vector length:', len(X_train[0]))\n",
    "    \n",
    "    # Use a linear SVC \n",
    "    svc = LinearSVC()\n",
    "    \n",
    "    # Training for the SVC\n",
    "    t=time.time()\n",
    "    svc.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "    \n",
    "    # Check the score of the SVC\n",
    "    print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "    \n",
    "    # Check the prediction time for a single sample\n",
    "    t=time.time()\n",
    "    n_predict = 10\n",
    "    print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "    print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')\n",
    "    \n",
    "    #save svc model\n",
    "    pickle_svc = {}\n",
    "    pickle_svc['X_scaler'] = X_scaler\n",
    "    pickle_svc['svc'] = svc\n",
    "    pickle.dump(pickle_svc, open('pickle_svc.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_train = svm(car_files,noncar_files,cspace=colorspace,spatial_size=spatial_size,hist_bins=hist_bins, \n",
    "         hist_range=hist_range,orient=orient,pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "         hog_channel=hog_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions for Image Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_color(img, conv='RGB2YCrCb'):\n",
    "    \"\"\"\n",
    "    color conversion for a image to different color space\n",
    "    \"\"\"\n",
    "    \n",
    "    if conv == 'RGB2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    if conv == 'BGR2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    if conv == 'RGB2LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "\n",
    "    \n",
    "def add_heat(heatmap, bbox_list):\n",
    "    \"\"\"\n",
    "    Add one to the heatmap for every bounding box.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes\n",
    "    \n",
    "def apply_threshold(heatmap, threshold):\n",
    "    \"\"\"\n",
    "    Apply heatmap threshold.  Zero out pixels if below the threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    \"\"\"\n",
    "    Base on the image labels, draw a bounding box around objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (255,0,0), 3)\n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that extract cars in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that can extract features using hog sub-sampling\n",
    "def find_cars(img, ystart, ystop, scale, X_scaler, svc, orient, pix_per_cell, cell_per_block, \n",
    "              spatial_size, hist_bins, print_flag='no'):\n",
    "    \"\"\"\n",
    "    This is the main pipeline to find a car.\n",
    "    1. Define a ROI region to search for cars on the image.\n",
    "    2. Scale image accordingly if scale is defined different than 1\n",
    "    3. Split the image to separate channels\n",
    "    4. Compute the hog features for the 3 image channels\n",
    "    5. Define numbers of blocks, steps and window. For every image patch, compute the hog features\n",
    "       for individual channel, stack them up, and combine with other color features.\n",
    "    6. Predict the final feature using pre-define svm.\n",
    "    7. Draw a rectangle bounding box around predicted features on image\n",
    "    8. Return draw image and list of bounding box.\n",
    "    \"\"\"\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    if (print_flag == 'yes'):\n",
    "        plt.title('ROI to search for car')\n",
    "        plt.imshow(img_tosearch)\n",
    "    img_tosearch = convert_color(img_tosearch, conv='RGB2YCrCb')\n",
    "    \n",
    "    if scale != 1:\n",
    "        img_shape = img_tosearch.shape\n",
    "        img_tosearch = cv2.resize(img_tosearch, (np.int(img_shape[1]/scale), np.int(img_shape[0]/scale)))\n",
    "#         plt.title('ROI to search for car after applying scale')\n",
    "#         plt.imshow(img_tosearch)\n",
    "        \n",
    "    ch1 = img_tosearch[:,:,0]\n",
    "    ch2 = img_tosearch[:,:,1]\n",
    "    ch3 = img_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell)-1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell)-1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "\n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell)-1 \n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    bbox_list=[]\n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(img_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((hog_features, spatial_features, hist_features)).reshape(1, -1))    \n",
    "            #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),3) \n",
    "                bbox_list.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "                \n",
    "    return draw_img,bbox_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with six test images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "spatial_size = (32,32)\n",
    "hist_range = (0,256)\n",
    "hist_bins = 32\n",
    "\n",
    "ystart = 400\n",
    "ystop = 656\n",
    "scales = [1.5]\n",
    "\n",
    "threshold = 1.5\n",
    "\n",
    "\n",
    "#restore svc model and X_scaler\n",
    "pickle_svc = pickle.load(open('pickle_svc.p', 'rb'))\n",
    "svc = pickle_svc['svc']\n",
    "X_scaler = pickle_svc['X_scaler']\n",
    "\n",
    "test_files = glob.glob('test_images/*.jpg')\n",
    "\n",
    "\n",
    "for test_file in test_files:\n",
    "    test_img = mpimg.imread(test_file)\n",
    "    heat = np.zeros_like(test_img[:,:,0]).astype(np.float)\n",
    "    \n",
    "    curr_img = np.copy(test_img)\n",
    "    for curr_scale in scales:\n",
    "        curr_img,box_list = find_cars(curr_img, ystart, ystop, curr_scale, X_scaler, svc, \n",
    "                                      orient, pix_per_cell, cell_per_block, spatial_size, \n",
    "                                      hist_bins, print_flag='no')\n",
    "        heat = add_heat(heat,box_list)\n",
    "        heat = apply_threshold(heat,threshold)\n",
    "        heatmap = np.clip(heat, 0, 255)\n",
    "    \n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    draw_image = draw_labeled_bboxes(np.copy(test_img), labels)\n",
    "    \n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(10,5))\n",
    "    \n",
    "    ax1.imshow(curr_img)\n",
    "    ax1.set_title('window search')\n",
    "    \n",
    "    ax2.imshow(heatmap, cmap='hot')\n",
    "    ax2.set_title('heatmap')\n",
    "    \n",
    "    ax3.imshow(draw_image)\n",
    "    ax3.set_title('bounding box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for test_file in test_files:\n",
    "    test_img = mpimg.imread(test_file)\n",
    "    _,_ = find_cars(test_img, ystart, ystop, curr_scale, X_scaler, svc, \n",
    "                                      orient, pix_per_cell, cell_per_block, spatial_size, \n",
    "                                      hist_bins, print_flag='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "#restore svc model and X_scaler\n",
    "pickle_svc = pickle.load(open('pickle_svc.p', 'rb'))\n",
    "svc = pickle_svc['svc']\n",
    "X_scaler = pickle_svc['X_scaler']\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "spatial_size = (32,32)\n",
    "hist_range = (0,256)\n",
    "hist_bins = 32\n",
    "ystart = 400\n",
    "ystop = 656\n",
    "scales = [1.5]\n",
    "threshold = 5\n",
    "num_frames = 5   # number of frame in the queue\n",
    "\n",
    "\n",
    "\n",
    "class HotWindows():\n",
    "    \"\"\"\n",
    "    Keep track of n previous hot windows\n",
    "    Compute cumulative heat map over time\n",
    "\n",
    "    self.windows is a queue of lists of bounding boxes.\n",
    "    The list can be of arbitrary size.\n",
    "    \n",
    "    Each element in the queue represents the list of\n",
    "    bounding boxes at a particular time frame.\n",
    "    \"\"\"\n",
    "    def __init__(self, n):\n",
    "        \"\"\"\n",
    "        constructor of the HotWindows class.\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        self.windows = []  \n",
    "\n",
    "    def add_windows(self, new_windows):\n",
    "        \"\"\"\n",
    "        Push new windows to queue\n",
    "        Pop from queue if it is full\n",
    "        \"\"\"\n",
    "        self.windows.append(new_windows)\n",
    "\n",
    "        queue_full = len(self.windows) >= self.n\n",
    "        if queue_full:\n",
    "            _ = self.windows.pop(0)\n",
    "\n",
    "    def get_windows(self):\n",
    "        \"\"\"\n",
    "        Concatenate all lists in the queue and return the list\n",
    "        \"\"\"\n",
    "        out_windows = []\n",
    "        for window in self.windows:\n",
    "            out_windows = out_windows + window\n",
    "        return out_windows\n",
    "    \n",
    "    \n",
    "hot_windows = HotWindows(num_frames)\n",
    "\n",
    "def process_image(img):\n",
    "    \"\"\"\n",
    "    Find the hot windows. Add the new windows from the new frame into the list\n",
    "    until the queue is full.\n",
    "    \n",
    "    Compute the heatmap base on hot windows, apply the heatmap threshold and find the labels \n",
    "    Finally, draw the bounding box around objects.\n",
    "    \n",
    "    \"\"\"\n",
    "    global hot_windows\n",
    "\n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    curr_img = np.copy(img)\n",
    "    for curr_scale in scales:\n",
    "        output_img,box_list = find_cars(curr_img, ystart, ystop, curr_scale, X_scaler, svc, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "        # Add new hot windows to HotWindows queue\n",
    "        hot_windows.add_windows(box_list)\n",
    "        all_hot_windows = hot_windows.get_windows()\n",
    "\n",
    "        # Calculate and draw heat map\n",
    "        heat = add_heat(heat, all_hot_windows)\n",
    "        heat = apply_threshold(heat, threshold)\n",
    "        labels = label(heat)\n",
    "\n",
    "        # Draw final bounding boxes\n",
    "        draw_img = draw_labeled_bboxes(np.copy(img), labels)\n",
    "        #draw_img = draw_labeled_bboxes(output_img, labels)\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "white_output = 'test_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"test_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "white_output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
